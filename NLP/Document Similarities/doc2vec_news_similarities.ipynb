{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Finding differences in similar news using doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from operator import itemgetter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "models_folder = 'models/'\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "\n",
    "Number of cores to use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "print('Number of cores=', cores)\n",
    "\n",
    "cores_to_use = cores - 1\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "\n",
    "Read the CSV file with all the news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    WASHINGTON  —   Congressional Republicans have...\n1    After the bullet shells get counted, the blood...\n2    When Walt Disney’s “Bambi” opened in 1942, cri...\n3    Death may be the great equalizer, but it isn’t...\nName: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "news_folder = 'data/'\n",
    "news_file = 'articles1.csv'\n",
    "\n",
    "news_df = pd.read_csv(news_folder+news_file)\n",
    "news_df = news_df['content']\n",
    "print(news_df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 50000\n"
     ]
    }
   ],
   "source": [
    "print('Total documents: %d' % news_df.shape[0])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Extract a subset of documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n0    WASHINGTON  —   Congressional Republicans have...\n1    After the bullet shells get counted, the blood...\n2    When Walt Disney’s “Bambi” opened in 1942, cri...\n3    Death may be the great equalizer, but it isn’t...\n4    SEOUL, South Korea  —   North Korea’s leader, ...\n5    LONDON  —   Queen Elizabeth II, who has been b...\nName: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "number_of_news_documents = 50000\n",
    "short_news_df = news_df[0:number_of_news_documents]\n",
    "print(short_news_df.shape)\n",
    "print(short_news_df.head(6))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "\n",
    "Create a duplicate \"news\" which is the half of text than the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del news_df\n",
    "duplicate = short_news_df[0]\n",
    "duplicate_half = int(len(duplicate)/2)+1\n",
    "duplicate = duplicate[duplicate_half:]\n",
    "\n",
    "# Append the \"duplicate\" news to the end\n",
    "short_news_df = short_news_df.append(pd.Series(duplicate), \n",
    "                                     ignore_index=True)\n",
    "\n",
    "#print(short_news_df[5])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": false
   },
   "level": 2,
   "source": [
    "Add 2 documents with related the same news, but written by different news agencies(msn and bloomberg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supreme Court nominee Brett Kavanaugh angrily and \"unequivocally\" denied sexually assaulting Christi\nSupreme Court nominee Brett Kavanaugh angrily, tearfully and \"unequivocally\" denied sexually assault\n(50005,)\n"
     ]
    }
   ],
   "source": [
    "docs_folder = 'documents/'\n",
    "texts = ['msn.txt', 'bloomberg.txt']\n",
    "\n",
    "for text in texts:\n",
    "    f = open(docs_folder+text, 'r')\n",
    "    lines = [line for line in f.readlines() if line.strip()]\n",
    "    # remove the first 2 (agency, title)\n",
    "    f.close()\n",
    "    lines = lines[2:]\n",
    "    lines = ' '.join(lines)\n",
    "    print(lines[:100])\n",
    "    \n",
    "    # Add the text as a new entry in the news_df\n",
    "    short_news_df = short_news_df.append(pd.Series(lines), \n",
    "                                     ignore_index=True)\n",
    "print(short_news_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The half document has the index 50002\nThe msn article has the index 50003\nThe bloomberg article has the index 50004\n"
     ]
    }
   ],
   "source": [
    "total_documents = short_news_df.shape[0]\n",
    "print('The half document has the index', total_documents-3)\n",
    "print('The msn article has the index', total_documents-2)\n",
    "print('The bloomberg article has the index', total_documents-1)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": false
   },
   "level": 2,
   "source": [
    "Get all the sentences in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences for the corpus: 1520898\nAverage number of sentences per document: 30.417960\n\nAs an example, this document has only 7 sentences\n1   LONDON  —   Queen Elizabeth II, who has been battling a cold for more than a week, missed a New Year’s Day church service at her country estate in Sandringham, Buckingham Palace said on Sunday.\n2   A week earlier, the queen, who is 90, missed a Christmas Day church service, for the first time since 1988, because of the illness.\n3   “The Queen does not yet feel ready to attend church as she is still recuperating from a heavy cold,” the palace said in a statement.\n4   The queen’s husband, Prince Philip, who had also been ill, was well enough to attend both services, in the church at Sandringham, which is in Norfolk, on the east coast of England.\n5   The queen, who ascended to the throne in 1952, became the world’s   monarch following the death of King Bhumibol Adulyadej of Thailand in October.\n6   She is also Britain’s   monarch, having last year surpassed Queen Victoria’s   reign.\n7   Her mother lived until the age of 101.\n"
     ]
    }
   ],
   "source": [
    "sentences_per_doc = {}\n",
    "text_sentences_per_doc = {}\n",
    "\n",
    "# convert series to dict\n",
    "data = short_news_df.to_dict()\n",
    "\n",
    "# Traverse each document and count how many sentences it has\n",
    "# put in a dictionary the {document_id: num_of_sentences}\n",
    "total_sentences = 0\n",
    "for k,v in data.items():\n",
    "    sentences = sent_tokenize(v, language='english')\n",
    "    #print(k, len(sentences))\n",
    "    sentences_per_doc[k]=len(sentences)\n",
    "    text_sentences_per_doc[k] = sentences\n",
    "    total_sentences = total_sentences + len(sentences)\n",
    "\n",
    "#print('Sentences per document')\n",
    "#print(sentences_per_doc)\n",
    "\n",
    "print('Total sentences for the corpus: %d' % total_sentences)\n",
    "print('Average number of sentences per document: %f' % \n",
    "      (total_sentences/number_of_news_documents))\n",
    "\n",
    "print()\n",
    "print('As an example, this document has only %d sentences' % sentences_per_doc[5])\n",
    "for i, sent in enumerate(text_sentences_per_doc[5]):\n",
    "    print(i+1,' ',sent)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": false
   },
   "level": 2,
   "source": [
    "Put a label for ech sentence which also identifies the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0_0', '0_1', '0_2', '0_3', '0_4', '0_5', '0_6', '0_7', '0_8', '0_9', '0_10', '0_11', '0_12', '0_13', '0_14', '0_15', '0_16', '0_17', '0_18', '0_19', '0_20', '0_21', '0_22', '0_23', '0_24', '0_25', '1_0', '1_1', '1_2', '1_3', '1_4', '1_5', '1_6', '1_7', '1_8', '1_9', '1_10', '1_11', '1_12', '1_13', '1_14', '1_15', '1_16', '1_17', '1_18', '1_19', '1_20', '1_21', '1_22', '1_23', '1_24', '1_25', '1_26', '1_27', '1_28', '1_29', '1_30', '1_31', '1_32', '1_33', '1_34', '1_35', '1_36', '1_37', '1_38', '1_39', '1_40', '1_41', '1_42', '1_43', '1_44', '1_45', '1_46', '1_47', '1_48', '1_49', '1_50', '1_51', '1_52', '1_53', '1_54', '1_55', '1_56', '1_57', '1_58', '1_59', '1_60', '1_61', '1_62', '1_63', '1_64', '1_65', '1_66', '1_67', '1_68', '1_69', '1_70', '1_71', '1_72', '1_73']\n\n"
     ]
    }
   ],
   "source": [
    "# Create a list with the labels for each sentence in each document\n",
    "# with the form: docid_sentid\n",
    "\n",
    "\n",
    "labels = []\n",
    "for k,v in sentences_per_doc.items():\n",
    "    initial_value = 0\n",
    "    end_value = initial_value + v\n",
    "    #print(k, initial_value, end_value, (v, end_value-initial_value))\n",
    "    for sent_id in range(initial_value, end_value):\n",
    "        #print(str(k) + '_' +str(sent_id))\n",
    "        label = str(k) + '_' +str(sent_id)\n",
    "        labels.append(label)\n",
    "    \n",
    "    initial_value = end_value\n",
    "\n",
    "print(labels[:100])\n",
    "##['0_0', '0_1', '0_2', '0_3', '0_4', '0_5', '0_6', '0_7', '0_8',...]\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": true
   },
   "level": 2,
   "source": [
    "Preprocessing each sentence, and put tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "def simple_preprocessing(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = sent.replace(\"—\",\"\")\n",
    "    sent = sent.replace('“', '')\n",
    "    sent = sent.replace('”','')\n",
    "    sent = sent.replace(\":\",\"\")\n",
    "    sent = sent.replace(\",\",\"\")\n",
    "    sent = sent.replace(\".\",\"\")\n",
    "    sent = sent.replace(\"(\",\"\")\n",
    "    sent = sent.replace(\")\",\"\")\n",
    "    \n",
    "     # remove stop words\n",
    "    #sent_no_stop_words = [word for word in sent.split() if word not in STOPWORDS]\n",
    "    #sent = ' '.join(sent_no_stop_words)\n",
    "    return sent\n",
    "\n",
    "def remove_stop_words(sent):\n",
    "    # remove stop words\n",
    "    sent_no_stop_words = [word for word in sent.split() if word not in STOPWORDS]\n",
    "    sent = ' '.join(sent_no_stop_words)\n",
    "    return sent\n",
    "\n",
    "\n",
    "#print(text_sentences_per_doc[1])\n",
    "#print(len(text_sentences_per_doc[1]))\n",
    "all_sentences = []\n",
    "for doc, text in text_sentences_per_doc.items():\n",
    "    for sent in text:\n",
    "        sent = simple_preprocessing(sent)\n",
    "        sent = remove_stop_words(sent)\n",
    "        all_sentences.append(sent)\n",
    "#print(all_sentences[:10])\n",
    "\n",
    "all_sentence_labels = zip(all_sentences, labels)\n",
    "#x_list = list(all_sentence_labels)\n",
    "#print(x_list[:5])\n",
    "\n",
    "# Make tuples (sentence, label). \n",
    "#[TaggedDocument(words=['i', 'love', 'machine', 'learningits', 'awesome'], tags=['0']),...\n",
    "\n",
    "# Tag the sentences \n",
    "tagged_data = [TaggedDocument(words=word_tokenize(sentence),\n",
    "                             tags= [label]) for sentence, label in all_sentence_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show how tagged sentences look like\nTaggedDocument(['complicated', 'set', 'dynamics', 'illustrating', 'quick', 'legal', 'victory', 'house', 'trump', 'era', 'might', 'come', 'costs', 'republicans', 'never', 'anticipated', 'took', 'obama', 'white', 'house'], ['0_25'])\n\ncomplicated set dynamics illustrating quick legal victory house trump era might come costs republicans never anticipated took obama white house\n\nIt is a complicated set of dynamics illustrating how a quick legal victory for the House in the Trump era might come with costs that Republicans never anticipated when they took on the Obama White House.\n"
     ]
    }
   ],
   "source": [
    "print(\"Show how tagged sentences look like\")\n",
    "print(tagged_data[25])\n",
    "print()\n",
    "print(all_sentences[25])\n",
    "print()\n",
    "print(short_news_df[0][-203:])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Create the Doc2vec model. Comment it out if it is already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nstart = time.time()\\n\\nmax_epochs = 100\\nvec_size = 300\\nalpha = 0.025\\nseed = 42\\ncontext_window = 30\\n\\nmodel = Doc2Vec(vector_size=vec_size, window=context_window, workers=cores_to_use, \\n                alpha=alpha, min_alpha=0.00025, min_count=1, dm=1, seed=seed)\\nmodel.build_vocab(tagged_data)\\n\\nfor epoch in range(max_epochs):\\n    print(\\'iteration {0}\\'.format(epoch))\\n    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\\n    # decrease the learning rate\\n    model.alpha -= 0.0002\\n    # fix the learning rate, no decay\\n    model.min_alpha = model.alpha\\n\\nmodel.save(models_folder+\"d2v.model\")\\nprint(\"Model saved\")\\n\\nprint(time.time() - start)\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start = time.time()\n",
    "\n",
    "max_epochs = 100\n",
    "vec_size = 300\n",
    "alpha = 0.025\n",
    "seed = 42\n",
    "context_window = 30\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size, window=context_window, workers=cores_to_use, \n",
    "                alpha=alpha, min_alpha=0.00025, min_count=1, dm=1, seed=seed)\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(models_folder+\"d2v.model\")\n",
    "print(\"Model saved\")\n",
    "\n",
    "print(time.time() - start)\n",
    "'''"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "\n",
    "Load a previously trined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load(models_folder+\"d2v.model\")  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "\n",
    "Show the vector for the sentence 23 of document 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.84445035e+00  7.21494198e-01  6.03644699e-02 -1.38297930e-01\n  5.91027141e-01  6.03812742e+00 -1.41148388e+00 -5.12961268e-01\n -2.42788410e+00  1.08142889e+00 -2.42075419e+00 -2.82275629e+00\n  1.95072663e+00 -2.44059587e+00  1.06435668e+00 -1.75341618e+00\n -1.37170851e-01  5.03636956e-01 -2.80203128e+00  2.74401736e+00\n -5.19004427e-02 -1.53500748e+00 -1.52062607e+00  7.98701167e-01\n  1.96566701e+00 -2.07759261e+00 -1.29905319e+00  7.58102119e-01\n -2.03614044e+00  6.26642704e-01 -3.06225002e-01 -5.98171532e-01\n  8.70930180e-02  1.01052117e+00  6.85774267e-01 -3.04163873e-01\n -3.79774714e+00  1.17267084e+00 -2.41367638e-01 -3.29442835e+00\n -2.16527796e+00  2.75537181e+00  1.09594011e+00  2.26118398e+00\n -2.08677697e+00  2.86010098e+00 -2.54139185e+00 -3.34972739e+00\n  6.14363074e-01  2.91762662e+00 -2.21987534e+00 -1.39930713e+00\n  2.68269444e+00 -1.82928455e+00  1.80063570e+00 -2.25001082e-01\n  2.74404502e+00 -6.63519919e-01  1.19418979e+00 -2.34047413e+00\n  6.40871227e-01 -4.54237080e+00  1.01158798e+00 -1.94324350e+00\n  2.64842010e+00 -5.02085034e-03  3.50345910e-01 -2.13741064e+00\n -9.50146914e-01 -2.30640560e-01  8.17168117e-01 -1.64800882e+00\n  5.77674246e+00 -8.30137283e-02 -1.63359690e+00  1.74288583e+00\n  1.10507870e+00 -1.43339741e+00  9.15549278e-01 -2.80251503e-01\n  1.81462795e-01  2.66682982e+00 -1.02705812e+00 -2.27276158e+00\n  2.80428708e-01 -9.01696026e-01  2.41797000e-01 -1.17441285e+00\n  8.53225350e-01 -1.04661918e+00 -5.53887725e-01 -2.39659524e+00\n -1.10114425e-01 -2.57236153e-01  1.53794253e+00  2.00081873e+00\n  3.34505677e+00  1.95517838e+00  3.82572937e+00  4.88036215e-01\n -3.73772168e+00 -1.44182432e+00 -1.66660666e+00  8.42762411e-01\n -2.71646887e-01  1.75969625e+00 -1.60577750e+00 -1.83318472e+00\n  2.48997696e-02 -1.42820251e+00  1.54241002e+00 -5.06891429e-01\n  2.91286886e-01  4.02512836e+00 -1.55351472e+00  1.18580437e+00\n  1.41812646e+00 -4.57648605e-01  5.46161830e-01  5.83493233e-01\n  3.30633193e-01  2.28657031e+00 -1.05605662e+00 -1.82627201e+00\n  1.87262118e+00 -9.47367668e-01  1.48969978e-01  3.34112763e+00\n  1.99812257e+00 -3.19892240e+00 -1.97856402e+00  1.31787181e+00\n -8.87534082e-01  1.78790092e+00 -2.25199342e+00 -1.09649384e+00\n  5.78021228e-01 -1.17097475e-01 -8.79435599e-01 -7.05725670e-01\n  9.81660962e-01  1.14783502e+00  2.17740219e-02 -3.76376319e+00\n -1.87319660e+00  9.91581738e-01 -6.14466429e-01  6.70500517e-01\n -2.26034582e-01 -4.77907300e-01  1.01468456e+00 -3.88374352e+00\n -4.91995722e-01  9.16674197e-01 -3.37727475e+00 -3.84458756e+00\n -2.56847477e+00 -2.41389513e+00  3.51530135e-01  6.47127032e-01\n -3.50128675e+00  2.26151228e+00  9.70633268e-01  2.55420589e+00\n  2.20314845e-01 -1.39962518e+00 -1.42529476e+00 -4.91760683e+00\n  2.11552954e+00  6.37033045e-01 -3.42678356e+00 -2.70472860e+00\n  2.18310404e+00  5.39802849e-01  4.41107243e-01 -3.63326883e+00\n  1.29656881e-01 -2.00695825e+00 -3.89371991e-01  1.87572384e+00\n -2.48884916e+00  5.65660191e+00  1.26094270e+00 -5.48956096e-01\n  6.15774870e-01  3.01397157e+00 -2.13659430e+00 -1.52068305e+00\n -2.00804973e+00  8.58909547e-01 -1.89107764e+00  4.39514637e+00\n -9.25481796e-01  4.56435114e-01 -1.01555020e-01 -1.69617498e+00\n  2.68551850e+00 -2.06733227e+00  3.97916496e-01  1.97288799e+00\n -3.89560878e-01 -5.24035394e-01 -2.71989465e+00  2.58788824e+00\n -2.73335719e+00  1.45817709e+00  1.84685004e+00 -1.31655723e-01\n  6.25958204e-01 -9.92663562e-01 -1.13311744e+00 -5.27774572e-01\n  1.00555992e+00 -3.42351258e-01 -8.29375267e-01 -2.57038999e+00\n  7.83235788e-01 -1.72926044e+00 -3.71818453e-01  1.91178048e+00\n -3.63606185e-01  1.85744688e-01  5.26091158e-01 -9.45018888e-01\n  3.62531877e+00  8.17374647e-01 -1.55985868e+00 -1.03077030e+00\n  1.09970784e+00  2.72826886e+00  9.94570460e-03  3.51185203e+00\n  4.30326670e-01  1.86879945e+00 -3.42339516e-01  1.14363241e+00\n  2.09336519e+00 -2.38237977e+00  2.14588307e-02 -2.18402576e+00\n -1.14369512e+00 -2.83272886e+00  3.58007741e+00 -3.41922545e+00\n -1.60005677e+00  2.00169992e+00  1.50351155e+00  1.68975580e+00\n  1.43283451e+00  2.43521762e+00 -5.71764171e-01 -3.99021339e+00\n -1.13224290e-01  8.15819681e-01  3.35245132e+00 -4.64343488e-01\n  1.39176571e+00 -1.15523016e+00 -1.13065803e+00  2.57848763e+00\n -2.98003531e+00 -1.39027035e+00 -2.70888472e+00  1.01064718e+00\n -2.07827306e+00 -5.81604660e-01 -4.86588287e+00  6.65110528e-01\n  9.18238103e-01  2.46804190e+00 -1.45814347e+00 -2.60387373e+00\n  1.56473112e+00  1.06903350e+00  1.24089003e+00 -1.59506130e+00\n  9.72426057e-01  1.66277373e+00  3.15770745e+00 -2.87449509e-01\n -1.48055995e+00  1.50774762e-01 -2.39745188e+00  1.36957824e+00\n  9.16566730e-01  3.34226638e-01  6.47209406e-01  3.74347520e+00\n  9.05069709e-01 -8.77201674e-04  9.24062192e-01 -3.69514370e+00\n  1.36118019e+00 -8.08849216e-01 -2.23415703e-01 -1.26702464e+00\n -3.63811994e+00  7.05974221e-01 -3.13107157e+00  3.71702909e-01]\n"
     ]
    }
   ],
   "source": [
    "print(model.docvecs['0_23'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Doc2vec uses word2vec. Do some test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words to obama\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/0a1cd6b4-4d6a-40d6-80be-a86f7c7fec17/Mega/Python/Group Recommender/environments/word2vec/lib/python3.5/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('trump', 0.509588897228241), ('incoming', 0.49790042638778687), ('bush', 0.4892093241214752), ('pence', 0.48554351925849915), ('netanyahu', 0.47789430618286133), ('kerry', 0.47299259901046753), ('congress', 0.46616506576538086), ('sisi', 0.4641965925693512), ('kaine', 0.45805624127388), ('ryan', 0.4576532244682312)]\n\nMost similar words to china\n[('beijing', 0.767208456993103), ('chinese', 0.761801540851593), ('japan', 0.6881505250930786), ('asia', 0.6422123908996582), ('pyongyang', 0.622802734375), ('nato', 0.6147975921630859), ('iran', 0.6020537614822388), ('india', 0.5979095101356506), ('europe', 0.5766202211380005), ('nuclear', 0.5762708783149719)]\n\nMost similar words to machine\n[('machines', 0.5711404085159302), ('computer', 0.4750906527042389), ('robot', 0.47467562556266785), ('cloud', 0.4681369364261627), ('computers', 0.4675503969192505), ('everything', 0.4641663730144501), ('stuff', 0.45496082305908203), ('camera', 0.45097923278808594), ('software', 0.4473637044429779), ('device', 0.44596341252326965)]\n\nMost similar words to good\n[('better', 0.7170074582099915), ('bad', 0.7089889049530029), ('great', 0.6871258616447449), ('best', 0.6620607376098633), ('kind', 0.6491948366165161), ('maybe', 0.6407602429389954), ('want', 0.6355602741241455), ('amazing', 0.6296908259391785), ('perfect', 0.6123157739639282), ('wonderful', 0.6087819933891296)]\n\nMost similar words to innocent\n[('kill', 0.5376931428909302), ('horrible', 0.5335644483566284), ('evil', 0.5264583230018616), ('horrific', 0.5245592594146729), ('violence', 0.5024935603141785), ('cruel', 0.4890521466732025), ('afraid', 0.48255491256713867), ('moral', 0.4791931211948395), ('brave', 0.47363734245300293), ('deserve', 0.46965837478637695)]\n\nMost similar words to guilty\n[('convicted', 0.6640106439590454), ('sentence', 0.6174924969673157), ('charges', 0.6002538800239563), ('trial', 0.5930036306381226), ('charged', 0.5891462564468384), ('prosecutors', 0.5757434964179993), ('conviction', 0.562496542930603), ('prison', 0.5413297414779663), ('sentenced', 0.537346363067627), ('indicted', 0.5299966335296631)]\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/0a1cd6b4-4d6a-40d6-80be-a86f7c7fec17/Mega/Python/Group Recommender/environments/word2vec/lib/python3.5/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n  # Remove the CWD from sys.path while we load stuff.\n/mnt/0a1cd6b4-4d6a-40d6-80be-a86f7c7fec17/Mega/Python/Group Recommender/environments/word2vec/lib/python3.5/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n  app.launch_new_instance()\n/mnt/0a1cd6b4-4d6a-40d6-80be-a86f7c7fec17/Mega/Python/Group Recommender/environments/word2vec/lib/python3.5/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n/mnt/0a1cd6b4-4d6a-40d6-80be-a86f7c7fec17/Mega/Python/Group Recommender/environments/word2vec/lib/python3.5/site-packages/ipykernel_launcher.py:28: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n/mnt/0a1cd6b4-4d6a-40d6-80be-a86f7c7fec17/Mega/Python/Group Recommender/environments/word2vec/lib/python3.5/site-packages/ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "word = 'obama'\n",
    "\n",
    "print('Most similar words to', word)\n",
    "print(model.most_similar(word))\n",
    "\n",
    "print()\n",
    "\n",
    "word = 'china'\n",
    "print('Most similar words to', word)\n",
    "print(model.most_similar(word))\n",
    "\n",
    "print()\n",
    "\n",
    "word = 'machine'\n",
    "print('Most similar words to', word)\n",
    "print(model.most_similar(word))\n",
    "\n",
    "print()\n",
    "\n",
    "word = 'good'\n",
    "print('Most similar words to', word)\n",
    "print(model.most_similar(word))\n",
    "\n",
    "print()\n",
    "\n",
    "word = 'innocent'\n",
    "print('Most similar words to', word)\n",
    "print(model.most_similar(word))\n",
    "print()\n",
    "\n",
    "word = 'guilty'\n",
    "print('Most similar words to', word)\n",
    "print(model.most_similar(word))\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": false
   },
   "level": 2,
   "source": [
    "Given a document and a sentece of that document, search in the corpus for the sentence that is more similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From document 12, check sentence number 5:\nAnd that was always the intention of Marjorie Meriweather Post, the cereal heiress and the property’s original owner, who left    to the federal government when she died in 1973, hoping it would serve as a home for presidents.\n\nThe most similar sentence is from document 3372 sentence number 8, with a probability of 0.453919:\nThere’s Mad Max’s Thunderdome, where gladiators died.\n"
     ]
    }
   ],
   "source": [
    "sentence_to_check = '12_5'\n",
    "original_doc, original_sentence = sentence_to_check.split(\"_\")\n",
    "print('From document %s, check sentence number %s:' % (original_doc, original_sentence))\n",
    "sentence = text_sentences_per_doc[int(original_doc)][int(original_sentence)]\n",
    "print(sentence)\n",
    "\n",
    "similar_docs = model.docvecs.most_similar(sentence_to_check)\n",
    "print()\n",
    "\n",
    "max_similar_doc, probability = max(similar_docs, key=itemgetter(1))\n",
    "\n",
    "similar_doc, similar_sentence = max_similar_doc.split(\"_\")\n",
    "\n",
    "#print(similar_doc, similar_sentence)\n",
    "print('The most similar sentence is from document %s sentence number %s, with a probability of %f:' % \n",
    "                                    (similar_doc, similar_sentence, probability))\n",
    "\n",
    "sentence = text_sentences_per_doc[int(similar_doc)][int(similar_sentence)]\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": false
   },
   "level": 2,
   "source": [
    "Recall where our intresting news were placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The half document has the index 50002\nThe msn article has the index 50003\nThe bloomberg article has the index 50004\n"
     ]
    }
   ],
   "source": [
    "total_documents = short_news_df.shape[0]\n",
    "print('The half document has the index', total_documents-3)\n",
    "print('The msn article has the index', total_documents-2)\n",
    "print('The bloomberg article has the index', total_documents-1)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "\n",
    "Find the most similar sentence for one of the test sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From document 0, check sentence number 20:\nHouse Republicans contend that Congress never appropriated the money for the subsidies, as required by the Constitution.\n\nThe most similar sentence is from document 50000 sentence number 7, with a probability of 0.975474:\nHouse Republicans contend that Congress never appropriated the money for the subsidies, as required by the Constitution.\n"
     ]
    }
   ],
   "source": [
    "sentence_to_check = '0_20'\n",
    "original_doc, original_sentence = sentence_to_check.split(\"_\")\n",
    "print('From document %s, check sentence number %s:' % (original_doc, original_sentence))\n",
    "sentence = text_sentences_per_doc[int(original_doc)][int(original_sentence)]\n",
    "print(sentence)\n",
    "\n",
    "similar_docs = model.docvecs.most_similar(sentence_to_check)\n",
    "print()\n",
    "\n",
    "max_similar_doc, probability = max(similar_docs, key=itemgetter(1))\n",
    "\n",
    "similar_doc, similar_sentence = max_similar_doc.split(\"_\")\n",
    "\n",
    "#print(similar_doc, similar_sentence)\n",
    "print('The most similar sentence is from document %s sentence number %s, with a probability of %f:' % \n",
    "                                    (similar_doc, similar_sentence, probability))\n",
    "\n",
    "sentence = text_sentences_per_doc[int(similar_doc)][int(similar_sentence)]\n",
    "print(sentence)\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Now, given two documents P and Q, let's try to see if Q has similar sentences to P.\n",
    "We want to simulate the case of if I read document P, should I read document Q?, what is different in Q?\n",
    "\n",
    "Q --> P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document P has 65 sentences\nDocument Q has 71 sentences\n\nSize of X=  (65, 300)\n\nSentences in document Q not similar those in document P are:\n\nSupreme Court nominee Brett Kavanaugh angrily, tearfully and \"unequivocally\" denied sexually assaulting Christine Blasey Ford, after she told senators at a dramatic hearing that she’s \"one hundred percent\" certain he is the one who attacked her when they were teenagers.\n\t\tThe most similar sentence is 0, with a similarity of 0.953718\nSupreme Court nominee Brett Kavanaugh angrily and \"unequivocally\" denied sexually assaulting Christine Blasey Ford, after she told senators at a dramatic hearing that she’s \"one hundred percent\" certain he is the one who attacked her when they were teenagers.\n\n\"I was not at the party described by Dr. Ford,\" Kavanaugh told the Senate Judiciary Committee Thursday as he tried to save his nomination in the face of public claims of sexual misconduct by three women.\n\t\tThe most similar sentence is 1, with a similarity of 0.990918\n\"I was not at the party described by Dr. Ford,\" Kavanaugh told the Senate Judiciary Committee Thursday as he tried to save his nomination in the face of public claims of sexual misconduct by three women.\n\n\"This confirmation process has become a national disgrace.\"\n\t\tThe most similar sentence is 2, with a similarity of 0.963409\n\"This confirmation process has become a national disgrace.\"\n\n\"I will not be intimidated into withdrawing from this process,\" Kavanaugh said.\n\t\tThe most similar sentence is 9, with a similarity of 0.708943\n\"This is a circus.\"\n\n\"I am innocent of this charge.\"\n\t\tThe most similar sentence is 9, with a similarity of 0.739682\n\"This is a circus.\"\n\nKavanaugh’s testimony gave senators a stark choice.\n\t\tThe most similar sentence is 3, with a similarity of 0.973754\nKavanaugh’s testimony gave senators a stark choice.\n\nEarlier in the day, Ford said her accusation was \"absolutely not\" a case of mistaken identity.\n\t\tThe most similar sentence is 4, with a similarity of 0.978438\nEarlier in the day, Ford said her accusation was \"absolutely not\" a case of mistaken identity.\n\nShe said the 1982 incident -- including the \"uproarious laughter\" of Kavanaugh and his friend who she says witnessed the attack -- was \"seared into my memory\" even though she didn’t remember all the details.\n\t\tThe most similar sentence is 5, with a similarity of 0.970136\nShe said the 1982 incident -- including the \"uproarious laughter\" of Kavanaugh and his friend who she says witnessed the attack -- was \"seared into my memory\" even though she didn’t remember all the details.\n\nThe Senate Judiciary Committee is scheduled to vote on Kavanaugh’s nomination Friday, and the full Senate could act as early as next week.\n\t\tThe most similar sentence is 6, with a similarity of 0.983526\nThe Senate Judiciary Committee is scheduled to vote on Kavanaugh’s nomination Friday, and the full Senate could act as early as next week.\n\nThe hearing marked the first time Ford had spoken publicly about her accusation, which could derail the confirmation, redefine the \"Me Too\" era and affect the fight for control of Congress in the Nov. 6 election.\n\t\tThe most similar sentence is 7, with a similarity of 0.986284\nThe hearing marked the first time Ford had spoken publicly about her accusation, which could derail the confirmation, redefine the \"Me Too\" era and affect the fight for control of Congress in the Nov. 6 election.\n\n\"This whole two-week effort has been a calculated and orchestrated political hit, fueled with apparently pent-up anger about President Trump and the 2016 election, fear that has been unfairly stoked about my judicial record, revenge on behalf of the Clintons and millions of dollars in money from outside, left-wing opposition groups,\" Kavanaugh told the committee.\n\t\tThe most similar sentence is 8, with a similarity of 0.981941\n\"This whole two-week effort has been a calculated and orchestrated political hit, fueled with apparently pent-up anger about President Trump and the 2016 election, fear that has been unfairly stoked about my judicial record, revenge on behalf of the Clintons and millions of dollars in money from outside, left-wing opposition groups,\" Kavanaugh told the committee.\n\n\"This is a circus.\"\n\t\tThe most similar sentence is 9, with a similarity of 0.959921\n\"This is a circus.\"\n\n\"I intend no ill will to Dr. Ford and her family,\" Kavanaugh said.\n\t\tThe most similar sentence is 10, with a similarity of 0.978666\n\"I intend no ill will to Dr. Ford and her family,\" Kavanaugh said.\n\nHe choked back tears while saying that his 10-year-old daughter, in saying her evening prayers recently, told Kavanaugh’s wife Ashley, \"we should pray for the woman.\"\n\t\tThe most similar sentence is 11, with a similarity of 0.980766\nHe choked back tears while saying that his 10-year-old daughter, in saying her evening prayers recently, told Kavanaugh’s wife Ashley, \"we should pray for the woman.\"\n\nThe nominee was tearful through portions of his opening statement: while expressing gratitude to his friends, saying he had no sexual intercourse until well after high school, and saying he drank beer in high school.\n\t\tThe most similar sentence is 11, with a similarity of 0.594582\nHe choked back tears while saying that his 10-year-old daughter, in saying her evening prayers recently, told Kavanaugh’s wife Ashley, \"we should pray for the woman.\"\n\n##################################################\nSo, are new ideas in this sentence? [1]=> The nominee was tearful through portions of his opening statement: while expressing gratitude to his friends, saying he had no sexual intercourse until well after high school, and saying he drank beer in high school.\n##################################################\n\n\"But I did not drink beer to the point of blacking out and I did not sexually assault anyone,\" he said.\n\t\tThe most similar sentence is 9, with a similarity of 0.663322\n\"This is a circus.\"\n\nKavanaugh said Ford’s allegation is \"refuted by the very people she says were there,\" including a female friend of Ford’s who says she doesn’t remember the party.\n\t\tThe most similar sentence is 12, with a similarity of 0.983942\nFord’s allegation is \"refuted by the very people she says were there,\" including a female friend of Ford’s who says she doesn’t remember the party, Kavanaugh said.\n\nHe said his calendar for the summer of 1982 \"shows all but definitely that I was not there.\"\n\t\tThe most similar sentence is 12, with a similarity of 0.613401\nFord’s allegation is \"refuted by the very people she says were there,\" including a female friend of Ford’s who says she doesn’t remember the party, Kavanaugh said.\n\n##################################################\nSo, are new ideas in this sentence? [2]=> He said his calendar for the summer of 1982 \"shows all but definitely that I was not there.\"\n##################################################\n\nIf an unproven allegation \"is enough to destroy a person’s life and career we will have abandoned the basic principles of fairness and due process that define our legal system and our country,\" Kavanaugh said.\n\t\tThe most similar sentence is 33, with a similarity of 0.586361\n\"I found no reason to find her not credible,\" Republican Senator John Cornyn of Texas said after Ford completed her testimony, though he said Kavanaugh’s \"reputation is on the line, his career as well.\"\n\n##################################################\nSo, are new ideas in this sentence? [3]=> If an unproven allegation \"is enough to destroy a person’s life and career we will have abandoned the basic principles of fairness and due process that define our legal system and our country,\" Kavanaugh said.\n##################################################\n\nFord said she was sure that Kavanaugh was the person who attacked her.\n\t\tThe most similar sentence is 13, with a similarity of 0.980428\nFord said she was sure that Kavanaugh was the person who attacked her.\n\n\"With what degree of certainty do you believe Brett Kavanaugh assaulted you?\"\n\t\tThe most similar sentence is 14, with a similarity of 0.981561\n\"With what degree of certainty do you believe Brett Kavanaugh assaulted you?\"\n\nDemocratic Senator Dick Durbin of Illinois asked Ford.\n\t\tThe most similar sentence is 15, with a similarity of 0.971885\nDemocratic Senator Dick Durbin of Illinois asked Ford.\n\n\"One hundred percent,\" she responded.\n\t\tThe most similar sentence is 16, with a similarity of 0.966553\n\"One hundred percent,\" she responded.\n\nRepublicans are looking for Kavanaugh to cement a conservative majority on the court, while Democrats say he could provide the fifth vote to overturn the Roe v. Wade decision that legalized abortion.\n\t\tThe most similar sentence is 17, with a similarity of 0.989307\nRepublicans are looking for Kavanaugh to cement a conservative majority on the court, while Democrats say he could provide the fifth vote to overturn the Roe v. Wade decision that legalized abortion.\n\nPresident Donald Trump watched the morning portion of the hearing from Air Force One and the afternoon session from the White House residence, aides said.\n\t\tThe most similar sentence is 18, with a similarity of 0.991715\nPresident Donald Trump watched the morning portion of the hearing from Air Force One and the afternoon session from the White House residence, aides said.\n\nWhite House Press Secretary Sarah Sanders said he hasn’t talked to Kavanaugh in a couple of days.\n\t\tThe most similar sentence is 19, with a similarity of 0.978295\nWhite House Press Secretary Sarah Sanders said he hasn’t talked to Kavanaugh in a couple of days.\n\nKavanaugh forcefully assailed the committee’s handling of Ford’s claims, saying that during the 11 days since the allegation became public, \"my family and my name have been totally and permanently destroyed by vicious and false accusations.\"\n\t\tThe most similar sentence is 20, with a similarity of 0.991384\nKavanaugh forcefully assailed the committee’s handling of Ford’s claims, saying that during the 11 days since the allegation became public, \"my family and my name have been totally and permanently destroyed by vicious and false accusations.\"\n\nFord, a California psychology professor, said the incident has \"haunted me episodically as an adult.\"\n\t\tThe most similar sentence is 21, with a similarity of 0.956565\nFord, a California psychology professor, said the incident has \"haunted me episodically as an adult.\"\n\nShe said she was \"terrified\" to testify before the committee and that she she \"agonized daily\" about whether to come forward with her claim.\n\t\tThe most similar sentence is 22, with a similarity of 0.973670\nShe said she was \"terrified\" to testify before the committee and that she she \"agonized daily\" about whether to come forward with her claim.\n\nFord said Kavanaugh’s friend, Mark Judge, was in the room during the attack and that the two were laughing at her.\n\t\tThe most similar sentence is 23, with a similarity of 0.981823\nFord said Kavanaugh’s friend, Mark Judge, was in the room during the attack and that the two were laughing at her.\n\nShe said she had an \"indelible\" memory of \"the uproarious laughter between the two, and their having fun at my expense.\"\n\t\tThe most similar sentence is 24, with a similarity of 0.965532\nShe said she had an \"indelible\" memory of \"the uproarious laughter between the two, and their having fun at my expense.\"\n\nSenate Richard Blumenthal, a Connecticut Democrat, brought Ford to tears when he thanked her for coming forward.\n\t\tThe most similar sentence is 25, with a similarity of 0.978910\nSenate Richard Blumenthal, a Connecticut Democrat, brought Ford to tears when he thanked her for coming forward.\n\n\"If we agree on nothing else today, I hope on a bipartisan basis we can agree on how much courage it has taken for you to come forward, and I think you have earned America’s gratitude,\" Blumenthal said.\n\t\tThe most similar sentence is 26, with a similarity of 0.991198\n\"If we agree on nothing else today, I hope on a bipartisan basis we can agree on how much courage it has taken for you to come forward, and I think you have earned America’s gratitude,\" Blumenthal said.\n\nFord silently mouthed, \"thank you.\"\n\t\tThe most similar sentence is 27, with a similarity of 0.949046\nFord silently mouthed, \"thank you.\"\n\nFord cried again when Democratic Senator Cory Booker of New Jersey called her \"heroic.\"\n\t\tThe most similar sentence is 28, with a similarity of 0.970536\nFord cried again when Democratic Senator Cory Booker of New Jersey called her \"heroic.\"\n\nDuring a break, GOP Senator Orrin Hatch of Utah said he still expects the Judiciary panel to vote on Kavanaugh Friday and expects him to be voted out favorably.\n\t\tThe most similar sentence is 29, with a similarity of 0.986776\nDuring a break, GOP Senator Orrin Hatch of Utah said he still expects the Judiciary panel to vote on Kavanaugh Friday and expects him to be voted out favorably.\n\nQuestioning of Ford proceeded in five-minute chunks.\n\t\tThe most similar sentence is 30, with a similarity of 0.947274\nQuestioning of Ford proceeded in five-minute chunks.\n\nOther than Committee Chairman Chuck Grassley, the committee’s Republicans stayed mum, each instead having Arizona sex-crimes prosecutor Rachel Mitchell ask questions during his allotted minutes.\n\t\tThe most similar sentence is 31, with a similarity of 0.981417\nOther than Committee Chairman Chuck Grassley, the committee’s Republicans stayed mum, each instead having Arizona sex-crimes prosecutor Rachel Mitchell ask questions during his allotted minutes.\n\nThe 11 Republicans on the committee are all men.\n\t\tThe most similar sentence is 32, with a similarity of 0.975668\nThe 11 Republicans on the committee are all men.\n\n\"I found no reason to find her not credible,\" Republican Senator John Cornyn of Texas said after Ford completed her testimony, though he said Kavanaugh’s \"reputation is on the line, his career as well.\"\n\t\tThe most similar sentence is 33, with a similarity of 0.986909\n\"I found no reason to find her not credible,\" Republican Senator John Cornyn of Texas said after Ford completed her testimony, though he said Kavanaugh’s \"reputation is on the line, his career as well.\"\n\nMitchell’s questioning presented a stark contrast to the sweeping statements of support from Democrats.\n\t\tThe most similar sentence is 34, with a similarity of 0.981904\nMitchell’s questioning presented a stark contrast to the sweeping statements of support from Democrats.\n\nMitchell spent most of her time trying to clarify details of Ford’s story, covering the night of the alleged assault and the professor’s decision to come forward by confidentially telling her congressional representative and the Washington Post.\n\t\tThe most similar sentence is 35, with a similarity of 0.992932\nMitchell spent most of her time trying to clarify details of Ford’s story, covering the night of the alleged assault and the professor’s decision to come forward by confidentially telling her congressional representative and the Washington Post.\n\nFord said that though they went to different high schools, she had been friendly with a classmate of Kavanaugh’s and attended a number of parties that the future judge also attended.\n\t\tThe most similar sentence is 36, with a similarity of 0.893916\nCharles Grassley delivers his opening statement.Photographer: Win McNamee/Getty Images Ford said that though they went to different high schools, she had been friendly with a classmate of Kavanaugh’s and attended a number of parties that the future judge also attended.\n\nShe said the attack occurred after she went upstairs to use the bathroom.\n\t\tThe most similar sentence is 37, with a similarity of 0.968482\nShe said the attack occurred after she went upstairs to use the bathroom.\n\nShe said she was pushed into a bedroom and onto a bed and that Kavanaugh got on top of her.\n\t\tThe most similar sentence is 38, with a similarity of 0.975871\nShe said she was pushed into a bedroom and onto a bed and that Kavanaugh got on top of her.\n\nJudge was in the room and encouraged the attack, she said.\n\t\tThe most similar sentence is 39, with a similarity of 0.962976\nJudge was in the room and encouraged the attack, she said.\n\n\"I believed he was going to rape me,\" Ford said.\n\t\tThe most similar sentence is 40, with a similarity of 0.969545\n\"I believed he was going to rape me,\" Ford said.\n\nKavanaugh put his hand on her mouth to keep her from screaming, she said, and because it was hard for her to breathe, \"I thought that Brett was accidentally going to kill me.\"\n\t\tThe most similar sentence is 41, with a similarity of 0.988111\nKavanaugh put his hand on her mouth to keep her from screaming, she said, and because it was hard for her to breathe, \"I thought that Brett was accidentally going to kill me.\"\n\nShe said Judge, who has denied any part in such an attack, jumped on them and she was able to escape.\n\t\tThe most similar sentence is 42, with a similarity of 0.985313\nShe said Judge, who has denied any part in such an attack, jumped on them and she was able to escape.\n\nAsked what she remembers from that night, Ford responded: \"The stairwell, the living room, the bedroom, the bed on the right side of the room as you walk into the room -- there was a bed to the right -- the bathroom in close proximity, the laughter -- the uproarious laughter -- and the multiple attempts to escape and the final ability to do so.\"\n\t\tThe most similar sentence is 43, with a similarity of 0.977680\nAsked what she remembers from that night, Ford responded: \"The stairwell, the living room, the bedroom, the bed on the right side of the room as you walk into the room -- there was a bed to the right -- the bathroom in close proximity, the laughter -- the uproarious laughter -- and the multiple attempts to escape and the final ability to do so.\"\n\nUnder questioning from Mitchell, Ford said she didn’t know how she got home that night.\n\t\tThe most similar sentence is 44, with a similarity of 0.988067\nUnder questioning from Mitchell, Ford said she didn’t know how she got home that night.\n\nShe said the party took place \"somewhere between\" her home and the Columbia Country Club, about 7 miles away.\n\t\tThe most similar sentence is 45, with a similarity of 0.984127\nShe said the party took place \"somewhere between\" her home and the Columbia Country Club, about 7 miles away.\n\nThe Washington Post previously reported she told the paper the party took place near the country club.\n\t\tThe most similar sentence is 46, with a similarity of 0.990782\nThe Washington Post previously reported she told the paper the party took place near the country club.\n\n\"Has anyone come forward to say to you, ‘Hey, remember, I was the one that drove you home’?\"\n\t\tThe most similar sentence is 47, with a similarity of 0.840125\nRachel Mitchell questions Christine Blasey Ford.Photographer: Michael Reynolds/Pool via Bloomberg \"Has anyone come forward to say to you, ‘Hey, remember, I was the one that drove you home’?\"\n\nMitchell asked.\n\t\tThe most similar sentence is 48, with a similarity of 0.959038\nMitchell asked.\n\n\"No,\" Ford responded.\n\t\tThe most similar sentence is 49, with a similarity of 0.956958\n\"No,\" Ford responded.\n\nShe said she didn’t have her driver’s license at the time.\n\t\tThe most similar sentence is 50, with a similarity of 0.974928\nShe said she didn’t have her driver’s license at the time.\n\n‘I Want to Apologize’\n In opening the hearing, Grassley said, \"I want to apologize to you both for the way you’ve been treated,\" referring to threats made against Ford and Kavanaugh after her allegation became public.\n\t\tThe most similar sentence is 51, with a similarity of 0.989601\n‘I Want to Apologize’\n In opening the hearing, Grassley said, \"I want to apologize to you both for the way you’ve been treated,\" referring to threats made against Ford and Kavanaugh after her allegation became public.\n\nAs she prepared to leave, he thanked her \"for your bravery coming out and trying to answer our questions as best you could remember.\"\n\t\tThe most similar sentence is 52, with a similarity of 0.988133\nAs she prepared to leave, he thanked her \"for your bravery coming out and trying to answer our questions as best you could remember.\"\n\nDemocratic Senator Dianne Feinstein of California thanked Ford for her \"strength and bravery in coming forward.\"\n\t\tThe most similar sentence is 53, with a similarity of 0.962536\nDemocratic Senator Dianne Feinstein of California thanked Ford for her \"strength and bravery in coming forward.\"\n\n\"This is not a trial for Dr. Ford,\" Feinstein said.\n\t\tThe most similar sentence is 54, with a similarity of 0.967561\n\"This is not a trial for Dr. Ford,\" Feinstein said.\n\n\"It’s a job interview for Judge Kavanaugh.\"\n\t\tThe most similar sentence is 55, with a similarity of 0.981835\n\"It’s a job interview for Judge Kavanaugh.\"\n\nFeinstein noted that two other accusers came forward in the last several days.\n\t\tThe most similar sentence is 56, with a similarity of 0.977627\nFeinstein noted that two other accusers came forward in the last several days.\n\nThey aren’t scheduled to testify before the committee.\n\t\tThe most similar sentence is 57, with a similarity of 0.964002\nThey aren’t scheduled to testify before the committee.\n\nA second woman, Deborah Ramirez of Colorado, claims Kavanaugh exposed himself to her at a drunken party when they were freshmen at Yale University.\n\t\tThe most similar sentence is 58, with a similarity of 0.986578\nA second woman, Deborah Ramirez of Colorado, claims Kavanaugh exposed himself to her at a drunken party when they were freshmen at Yale University.\n\nAnd in the most lurid allegation yet, Julie Swetnick of Washington said in a sworn statement released Wednesday that Kavanaugh took part in efforts during high school to get girls intoxicated so that a group of boys could have sex with them.\n\t\tThe most similar sentence is 59, with a similarity of 0.985863\nAnd in the most lurid allegation yet, Julie Swetnick of Washington said in a sworn statement released Wednesday that Kavanaugh took part in efforts during high school to get girls intoxicated so that a group of boys could have sex with them.\n\nRepublicans are trying to get Kavanaugh, 53, confirmed as early as next week.\n\t\tThe most similar sentence is 60, with a similarity of 0.741971\nKavanaugh, Accuser Face Tough Senate Questioners in Both Parties\n Republicans are trying to get Kavanaugh, 53, confirmed as early as next week.\n\nRepublicans hold a 51-49 advantage in the Senate and can’t afford more than one defection to ensure confirmation without Democratic support.\n\t\tThe most similar sentence is 61, with a similarity of 0.979451\nRepublicans hold a 51-49 advantage in the Senate and can’t afford more than one defection to ensure confirmation without Democratic support.\n\nSeveral GOP lawmakers who remain publicly undecided -- most notably Alaska’s Lisa Murkowski, Maine’s Susan Collins and Arizona’s Jeff Flake -- said they wanted to hear what Ford has to say before making up their minds.\n\t\tThe most similar sentence is 62, with a similarity of 0.975428\nSeveral GOP lawmakers who remain publicly undecided -- most notably Alaska’s Lisa Murkowski, Maine’s Susan Collins and Arizona’s Jeff Flake -- said they wanted to hear what Ford has to say before making up their minds.\n\nCapitol police imposed strict security measures to keep protesters at bay after about 70 people were arrested each day during Kavanaugh’s earlier hearing.\n\t\tThe most similar sentence is 63, with a similarity of 0.987250\nCapitol police imposed strict security measures to keep protesters at bay after about 70 people were arrested each day during Kavanaugh’s earlier hearing.\n\nAt Ford’s request, the hearing was held in a smaller room with less space for media and the public, and protesters were being kept off that floor of the office building.\n\t\tThe most similar sentence is 64, with a similarity of 0.990760\nAt Ford’s request, the hearing was held in a smaller room with less space for media and the public, and protesters were being kept off that floor of the office building.\n\n"
     ]
    }
   ],
   "source": [
    "doc_P = 50001    # 0 Complete document    <- This is read first\n",
    "doc_Q = 50002    # number_of_news_documents <= ~Half of document 0 <- Should I read this later?\n",
    "\n",
    "\n",
    "def similarity_between_sentences(model, vec_sent_q):\n",
    "    return model.kneighbors(vec_sent_q.reshape(1, -1), return_distance=True)\n",
    "\n",
    "\n",
    "def print_if_similar(doc, doc_Q, sent_q, sent, distance):\n",
    "    d = 1 / (1+distance)\n",
    "    if d > 0.65:\n",
    "        ##print('***',text_sentences_per_doc[doc][sent])\n",
    "        ##print()\n",
    "        pass\n",
    "    else:\n",
    "        no_similars.append((doc_Q, sent_q))\n",
    "        sentence = text_sentences_per_doc[doc_Q][sent_q]\n",
    "        #sent_label = str(doc_Q) + \"_\" + str(sent_q)\n",
    "        print('#' * 50)\n",
    "        print('So, are new ideas in this sentence? [%d]=> %s' % (len(no_similars),sentence))\n",
    "        print('#' * 50)\n",
    "        print()\n",
    "        \n",
    "        \n",
    "total_sentences_P = sentences_per_doc[doc_P]\n",
    "total_sentences_Q = sentences_per_doc[doc_Q]\n",
    "\n",
    "print('Document P has %d sentences' % total_sentences_P)\n",
    "print('Document Q has %d sentences' % total_sentences_Q)\n",
    "print()\n",
    "\n",
    "# Need an array X with all the sentence vector for P\n",
    "X = []\n",
    "\n",
    "for id_sent in range(total_sentences_P):\n",
    "    sent_label = str(doc_P) + \"_\" + str(id_sent)\n",
    "    sent_vector = model.docvecs[sent_label]\n",
    "    X.append(sent_vector)\n",
    "\n",
    "X = np.array(X)\n",
    "print('Size of X= ',X.shape)\n",
    "knn = NearestNeighbors(n_neighbors=1, metric='cosine')\n",
    "knn.fit(X)\n",
    "\n",
    "print()\n",
    "no_similars = []\n",
    "\n",
    "print('Sentences in document Q not similar those in document P are:\\n')\n",
    "for sent_q in range(total_sentences_Q):\n",
    "    sentence = text_sentences_per_doc[doc_Q][sent_q]\n",
    "    sent_label = str(doc_Q) + \"_\" + str(sent_q)\n",
    "    #print(sent_label, sentence)\n",
    "    sent_vector = model.docvecs[sent_label]\n",
    "    distance, nearest_sent = similarity_between_sentences(knn, sent_vector)\n",
    "    \n",
    "    print(sentence)\n",
    "    print('\\t\\tThe most similar sentence is %d, with a similarity of %f' % (nearest_sent[0][0], \n",
    "                                                                        (1/(1+distance[0][0]))))    \n",
    "    print(text_sentences_per_doc[doc_P][nearest_sent[0][0]])\n",
    "    print()\n",
    "    \n",
    "\n",
    "    print_if_similar(doc_P, doc_Q, sent_q, nearest_sent[0][0], distance[0][0])\n",
    "    \n",
    "#print('%d sentences in document Q are different from document P' % len(no_similars))\n",
    "#print('Document Q is %.2f %% similar to document P' % \n",
    "#                        ( ((total_sentences_P - len(no_similars))/total_sentences_P)*100 ))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "So, from the similar sentences in both news find the keyphrases"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Keyword extraction RAKE\n"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 3,
   "source": [
    "The score is calculated Freq(word)/Degree(word)\n",
    "https://codelingo.wordpress.com/2017/05/26/keyword-extraction-using-rake/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the nominee was tearful through portions of his opening statement while expressing gratitude to his friends saying he had no sexual intercourse until well after high school and saying he drank beer in high school\n(4.0, 'sexual intercourse')\n\nhe said his calendar for the summer of 1982 \"shows all but definitely that i was not there\"\n(1.0, 'summer')\n\nif an unproven allegation \"is enough to destroy a person’s life and career we will have abandoned the basic principles of fairness and due process that define our legal system and our country\" kavanaugh said\n(4.0, 'unproven allegation')\n\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "r = Rake()\n",
    "\n",
    "#print(no_similars)\n",
    "\n",
    "for no_sim in no_similars:\n",
    "    doc, sent = no_sim\n",
    "    text = text_sentences_per_doc[doc][sent]\n",
    "    text = simple_preprocessing(text)\n",
    "    print(text)\n",
    "    \n",
    "    r.extract_keywords_from_text(text)\n",
    "    r.get_ranked_phrases()\n",
    "    print(r.get_ranked_phrases_with_scores()[0])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Text Summarization GenSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the nominee was tearful through portions of his opening statement while expressing gratitude to his friends saying he had no sexual intercourse until well after high school and saying he drank beer in high school\nKeywords\nfriends saying\n\nhe said his calendar for the summer of 1982 \"shows all but definitely that i was not there\"\n\nif an unproven allegation \"is enough to destroy a person’s life and career we will have abandoned the basic principles of fairness and due process that define our legal system and our country\" kavanaugh said\nKeywords\nkavanaugh\n\n"
     ]
    }
   ],
   "source": [
    "for no_sim in no_similars:\n",
    "    doc, sent = no_sim\n",
    "    text = text_sentences_per_doc[doc][sent]\n",
    "    text = simple_preprocessing(text)\n",
    "    print(text)\n",
    "    if keywords(text):\n",
    "        print('Keywords')\n",
    "        print(keywords(text))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Keyphrase using POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the nominee was tearful through portions of his opening statement while expressing gratitude to his friends saying he had no sexual intercourse until well after high school and saying he drank beer in high school\nKeywords\nnominee,portions,statement,gratitude,friends,intercourse,school,beer,school\n\nhe said his calendar for the summer of 1982 \"shows all but definitely that i was not there\"\nKeywords\ncalendar,summer,i\n\nif an unproven allegation \"is enough to destroy a person’s life and career we will have abandoned the basic principles of fairness and due process that define our legal system and our country\" kavanaugh said\nKeywords\nallegation,person,’,life,career,principles,fairness,process,system,country,kavanaugh\n\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "#sentence = \"At eight o'clock on Thursday film morning word line test best beautiful Ram Aaron design\"\n",
    "\n",
    "def extract_nouns_from_POS(sent):\n",
    "    nouns = [token for token, pos in pos_tag(word_tokenize(sent)) if pos.startswith('N')]\n",
    "    return nouns\n",
    "\n",
    "for no_sim in no_similars:\n",
    "    doc, sent = no_sim\n",
    "    text = text_sentences_per_doc[doc][sent]\n",
    "    text = simple_preprocessing(text)\n",
    "    print(text)\n",
    "    if extract_nouns_from_POS(text):\n",
    "        print('Keywords')\n",
    "        print(','.join(extract_nouns_from_POS(text)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 2,
   "source": [
    "Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk import RegexpParser\n",
    "\n",
    "def extract_NN(sent):\n",
    "    grammar = r\"\"\"\n",
    "    NBAR:\n",
    "        # Nouns and Adjectives, terminated with Nouns\n",
    "        #{<NN.*>*<NN.*>}\n",
    "        {<NN.*|JJ>*<NN.*>}  # Nouns and Adjectives, terminated with Nouns\n",
    "\n",
    "    NP:\n",
    "        {<NBAR>}\n",
    "        # Above, connected with in/of/etc...\n",
    "        {<NBAR><IN><NBAR>}\n",
    "    \"\"\"\n",
    "    chunker = RegexpParser(grammar)\n",
    "    ne = set()\n",
    "    chunk = chunker.parse(pos_tag(word_tokenize(sent)))\n",
    "    for tree in chunk.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "        ne.add(' '.join([child[0] for child in tree.leaves()]))\n",
    "    return ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for no_sim in no_similars:\n",
    "    doc, sent = no_sim\n",
    "    text = text_sentences_per_doc[doc][sent]\n",
    "    text = simple_preprocessing(text)\n",
    "    print(text)\n",
    "    if extract_NN(text):\n",
    "        print('Keywords')\n",
    "        print(extract_NN(text))\n",
    "    print()\n",
    "\n",
    "#text = 'the black dog is brave'\n",
    "#print(extract_NN(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
